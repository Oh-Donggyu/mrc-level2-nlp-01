{"cells":[{"cell_type":"markdown","metadata":{"id":"WjDdziEN_VCt"},"source":["# Passage Retrieval 구현하기"]},{"cell_type":"markdown","metadata":{"id":"Jm9gQPjOWKki"},"source":["이번 과제에서는 3강에서 배운 **Sparse Passage Retrieval** 과 4강에서 배운 **Dense Passage Retrieval (DPR)** 을 구현해봅니다. \n","\n","Passage Retrieval 을 다시 복습해보면,\n","1. Query와 Passage 를 임베딩 시킨 후\n","2. 임베딩된 벡터들에 각각 dot product를 수행하여 유사도를 구한 후에\n","3. 유사도가 가장 높은 passage 들을 검색 대상으로 합니다.   \n","\n","이 때 임베딩 시키는 방법에서 Sparse 와 Dense 가 나누어진 점, 다들 기억하시죠?\n","차근차근 구현해본 후, 전체 Wikipedia 에 대해서도 작업해봅시다."]},{"cell_type":"markdown","metadata":{"id":"2ug7dthenVCR"},"source":["```\n","🛠 Setup을 하는 부분입니다. 이전 과제에서 반복되는 부분이기 때문에 무지성 실행 하셔도 좋습니다.\n","💻 실습 코드입니다. 따라가면서 코드를 이해해보세요.\n","❓ 과제입니다. 주어진 질문과 요구사항에 맞춰서 직접 코드를 짜보세요.\n","```"]},{"cell_type":"markdown","metadata":{"id":"HKIvUE3FcdK6"},"source":["## 🛠 초기설정"]},{"cell_type":"markdown","metadata":{"id":"1NWluWk3_VCu"},"source":["### 🛠 Requirements"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"eGqFS4EEBF_Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n","Requirement already satisfied: numpy in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (1.21.2)\n","Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n","Requirement already satisfied: pandas in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (1.3.3)\n","Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (from pandas) (2021.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (from pandas) (1.21.2)\n","Requirement already satisfied: six>=1.5 in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n","Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n","Collecting sklearn\n","  Downloading http://mirror.kakao.com/pypi/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz (1.1 kB)\n","Collecting scikit-learn\n","  Downloading http://mirror.kakao.com/pypi/packages/f2/1d/0cc755ffc011b75ad7027095961a252628c315fd842d89235a3c3c06b2a4/scikit_learn-1.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.8 MB)\n","\u001b[K     |████████████████████████████████| 25.8 MB 18.2 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.21.2)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading http://mirror.kakao.com/pypi/packages/ff/fe/8aaca2a0db7fd80f0b2cf8a16a034d3eea8102d58ff9331d2aaf1f06766a/threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n","Collecting scipy>=1.1.0\n","  Downloading http://mirror.kakao.com/pypi/packages/0f/02/dac61d8f7e32fa803b6fa57a7daffb0d2993efde8503aca29082f1d1ce87/scipy-1.7.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n","\u001b[K     |████████████████████████████████| 28.4 MB 41.0 MB/s \n","\u001b[?25hUsing legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n","Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n","    Running setup.py install for sklearn ... \u001b[?25ldone\n","\u001b[?25hSuccessfully installed scikit-learn-1.0 scipy-1.7.1 sklearn-0.0 threadpoolctl-3.0.0\n","Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n","Collecting torch\n","  Downloading http://mirror.kakao.com/pypi/packages/28/58/6e420d2a0ac7962f35a60505f25c948c8a22d4204f5b1ff5e565e552404c/torch-1.9.1-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 83.5 MB/s \n","\u001b[?25hCollecting typing-extensions\n","  Downloading http://mirror.kakao.com/pypi/packages/74/60/18783336cc7fcdd95dae91d73477830aa53f5d3181ae4fe20491d7fc3199/typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Installing collected packages: typing-extensions, torch\n","Successfully installed torch-1.9.1 typing-extensions-3.10.0.2\n"]}],"source":["!pip install tqdm==4.48.0 -q\n","!pip install datasets==1.4.1 -q\n","!pip install transformers==4.5.0 -q\n","!pip install numpy\n","!pip install pandas\n","!pip install sklearn\n","!pip install torch"]},{"cell_type":"markdown","metadata":{"id":"xHf4ReA9dzyp"},"source":["### 🛠 난수 고정 및 버전 확인"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T08:06:13.948236Z","start_time":"2021-09-15T08:06:12.672812Z"},"id":"fNEhsdR6hM-6"},"outputs":[],"source":["import json\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm, trange\n","from pprint import pprint\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn.functional as F\n","\n","from datasets import load_dataset\n","from transformers import (\n","    AutoTokenizer,\n","    BertModel, BertPreTrainedModel,\n","    AdamW, get_linear_schedule_with_warmup,\n","    TrainingArguments,\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T08:06:13.978267Z","start_time":"2021-09-15T08:06:13.951238Z"},"id":"sSyEXp19d0L1"},"outputs":[],"source":["# 난수 고정\n","def set_seed(random_seed):\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    \n","set_seed(42) # magic number :)"]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T08:06:14.023236Z","start_time":"2021-09-15T08:06:13.979238Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1632397080665,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"jsayd5Ite-KY","outputId":"3c93060d-21a2-4e17-b0a6-b0c616c86e67"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch version:[1.9.1+cu102].\n","device:[cuda:0].\n"]}],"source":["print (\"PyTorch version:[%s].\"% (torch.__version__))\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print (\"device:[%s].\"%(device))"]},{"cell_type":"markdown","metadata":{"id":"CYUkp06Y_VCv"},"source":["### 🛠 데이터셋 로딩\n"]},{"cell_type":"markdown","metadata":{"id":"KMrZa4uql_nx"},"source":["KorQuAD 의 train 데이터를 학습 데이터로 활용"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:52:46.968793Z","start_time":"2021-09-15T06:52:28.974382Z"},"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["62521bb1e4aa482d8a9cc70b8b0f05f4","0a8da4314be14db2a420e066d15c4a18","3d2611ad087246688c3fc7b9b7c53b40","c57cd63b63644d4b8816a596cc039f4f","ebbbcf5247b14377ba5594c4b5f0762d","ba00bee158e143bfbb25629b6f296839","614f4194be844ee8bd4432365f7aceff","3a22cf7e6c644987994e3e0461656c55","e7ea0c6822dd4e409f935facb5368857","83ae8317c78a4e3ea673e34f16c4c0ab","d93e9ad555854bbbb020482c3c929444"]},"executionInfo":{"elapsed":10183,"status":"ok","timestamp":1632397090842,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"4IUxepuj_VCv","outputId":"a96b3c12-d9f5-4140-a15d-9e4fc4935394"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7798bea6edff464a949532f51324c605","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1745.0, style=ProgressStyle(description…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe8c2bb3b813410d8d808e93df2ca0f7","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=962.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Downloading and preparing dataset squad_kor_v1/squad_kor_v1 (download: 40.44 MiB, generated: 87.40 MiB, post-processed: Unknown size, total: 127.84 MiB) to /home/ubuntu/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba03c43dd52542aab2fd22c6412e6284","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=7568316.0, style=ProgressStyle(descript…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10fcc1e979aa41eca1925ad6b13b5236","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=770480.0, style=ProgressStyle(descripti…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b577161058704aa5938e182607882ef3","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1298a704b6094599837a37d8eccd3f33","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset squad_kor_v1 downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7. Subsequent calls will reuse this data.\n","총 9606개의 지문이 있습니다.\n"]}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"squad_kor_v1\")\n","corpus = list(set([example[\"context\"] for example in dataset[\"train\"]]))\n","print(f\"총 {len(corpus)}개의 지문이 있습니다.\")"]},{"cell_type":"markdown","metadata":{"id":"lJtECqpB_VCx"},"source":["### 🛠 토크나이저 준비 - Huggingface 제공 tokenizer 이용"]},{"cell_type":"markdown","metadata":{"id":"X0Fu2WaqpUB8"},"source":["BERT 를 encoder 로 사용하므로, KLUE에서 제공하는 `klue/bert-base` tokenizer 를 활용해봅시다. 다른 pretrained 모델을 사용하고 싶으시다면, `model_checkpoint`를 바꿔보세요 !"]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:52:56.152836Z","start_time":"2021-09-15T06:52:46.970795Z"},"id":"AoB8BHGDmVIK"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3dd306615941441395e5590af9602427","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=428.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28310189aae1455b8e7bb2acd2a4c5e9","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=248477.0, style=ProgressStyle(descripti…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d50f6a86a4549988f8620beef42fecd","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=125.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2967db1273d42e685c843e5121739e2","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=289.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["from transformers import AutoTokenizer\n","\n","model_checkpoint = \"klue/bert-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"X48czRQwcxPu"},"source":["불러온 Tokenzier가 잘 작동하는지 확인해봅시다."]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:52:56.182781Z","start_time":"2021-09-15T06:52:56.153749Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1632397095688,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"0U7sn3jsu44O","outputId":"d0d47a17-75c0-42fd-9ca6-f0264215a0d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["('[CLS] 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. '\n"," '이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 [UNK] 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 '\n"," '심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 '\n"," '받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 '\n"," '라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 '\n"," '받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 '\n"," '완성과 동시에 그는 이 서곡 ( 1악장 ) 을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. '\n"," '결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 '\n"," '방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 '\n"," '의견도 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]')\n"]}],"source":["tokenized_input = tokenizer(\n","    dataset[\"train\"][0][\"context\"],\n","    padding=\"max_length\",\n","    truncation=True\n",")\n","pprint(tokenizer.decode(tokenized_input[\"input_ids\"]))"]},{"cell_type":"markdown","metadata":{"id":"ZGPpy1Hpd_7m"},"source":["## 💻 Ⅰ. Sparse Retriever 실습\n","첫 번째로 TF-IDF 를 통해 임베딩 벡터를 만들어봅시다. 이 모듈은 직접 구현할 필요 없이 `sklearn.feature_extract.text` 에서 구현된 것을 사용합시다!\n","\n","더 간단하게 임베딩 벡터를 구할 수 있습니다.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UCeRbHPvh8UB"},"source":["### 💻 1. TF-IDF 학습하기\n","TF-IDF 사용법은 sklearn 홈페이지에서 확인할 수 있습니다. 제공된 링크를 읽어보시면, 아래에 작성된 코드를 쉽게 이해하실 수 있을 거에요.\n","\n","\n","*   [TF-IDF 공식 홈페이지](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n","*   [TF-IDF 사용 예시](https://wikidocs.net/31698)"]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:52:56.197781Z","start_time":"2021-09-15T06:52:56.183749Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1632395778137,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"WSQWisY2fUgV","outputId":"1db0cf43-ec13-4423-87e3-e80a17c45105"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------ 기존 문장 ------------------------------\n","('단, 선고 후 대통령이 사면해서 감옥에서는 풀려나왔지만 복권은 되지 않았다.그러나 선거에서 군사측이였던 우파가 지식인 측인 좌파에 패배, '\n"," '즉시 1904년에 재심이 청구되었고 1906년에 드레퓌스의 무죄가 선고되어 모든 혐의를 벗고, 복권도 되어 육군에 복직했다. 그 이후 '\n"," '소령으로 승진함은 물론, 레지옹 도뇌르 훈장까지 받게 된다. 제1차 세계 대전에도 참전하고 진급도 하고 일반 군인들처럼 생활하다가 '\n"," '1935년에 지병으로 별세했다.그러나 이 사건은 드레퓌스 자신에 삶에 너무나도 큰 상처를 입었고, 그 후에도 우파는 끝까지 드레퓌스의 '\n"," '유죄를 외쳤다. 그러면서 드레퓌스의 상처는 더 심해지는 그 당시 반유대주의와 반도이칠란드 주의가 낳은 최악의 결과였다.')\n","\n","------------------------------ Tokenize 된 문장 ------------------------------\n","('단 , 선고 후 대통령 ##이 사면 ##해서 감옥 ##에서 ##는 풀려나 ##왔 ##지만 복권 ##은 되 ##지 않 ##았 ##다 . '\n"," '그러나 선거 ##에서 군사 ##측 ##이 ##였 ##던 우파 ##가 지식인 측 ##인 좌파 ##에 패배 , 즉시 1904 ##년 ##에 '\n"," '재심 ##이 청구 ##되 ##었 ##고 1906 ##년 ##에 [UNK] 무죄 ##가 선고 ##되 ##어 모든 혐의 ##를 벗 ##고 , '\n"," '복권 ##도 되 ##어 육군 ##에 복직 ##했 ##다 . 그 이후 소령 ##으로 승진 ##함 ##은 물론 , 레지 ##옹 도 ##뇌 '\n"," '##르 훈장 ##까 ##지 받 ##게 된다 . 제 ##1 ##차 세계 대전 ##에도 참전 ##하고 진급 ##도 하고 일반 군인 ##들 '\n"," '##처럼 생활 ##하 ##다가 1935 ##년 ##에 지병 ##으로 별세 ##했 ##다 . 그러나 이 사건 ##은 [UNK] 자신 ##에 '\n"," '삶 ##에 너무나 ##도 큰 상처 ##를 입 ##었 ##고 , 그 후 ##에도 우파 ##는 끝 ##까 ##지 [UNK] 유죄 ##를 외쳤 '\n"," '##다 . 그러면 ##서 [UNK] 상처 ##는 더 심해 ##지 ##는 그 당시 반 ##유 ##대 ##주의 ##와 반도 ##이 ##칠 '\n"," '##란드 주의 ##가 낳 ##은 최악 ##의 결과 ##였 ##다 .')\n"]}],"source":["# Huggingface의 Tokenizer를 사용하셔도 좋고\n","tokenizer_func = lambda x: tokenizer.tokenize(x)\n","\n","# 혹은 단순 띄어쓰기 기준으로 Tokenize 하셔도 좋습니다.\n","# tokenizer_func = lambda x: x.split(' ')\n","\n","# 어떻게 Tokenize 되었는지 확인해봅시다.\n","print(f\"{'-'*30} 기존 문장 {'-'*30}\")\n","pprint(corpus[20])\n","print(f\"\\n{'-'*30} Tokenize 된 문장 {'-'*30}\")\n","pprint(\" \".join(tokenizer_func(corpus[20])))"]},{"cell_type":"markdown","metadata":{"id":"5LZR8COph2g9"},"source":["모듈을 활용해서 `fit` 해봅시다. 과정은 어렵지 않습니다."]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:53:20.560497Z","start_time":"2021-09-15T06:52:56.198781Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27861,"status":"ok","timestamp":1632395809641,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"OyQ290Cdd64F","outputId":"4a667585-8721-49b9-c1ed-5a71e697cc32"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n","/home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n","  warnings.warn(\n"]}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer(\n","    tokenizer=tokenizer_func,\n","    ngram_range=(1,2)\n",")\n","vectorizer.fit(corpus)\n","sp_matrix = vectorizer.transform(corpus)"]},{"cell_type":"markdown","metadata":{"id":"g4sPODsJ76xm"},"source":["`Vectorizer`로 임베딩을 시켜주면 (문서의 개수, 단어의 개수) 꼴의 행렬로 변환이 됩니다. 기본적으로 단어의 개수는 지정해주지 않으면 전체 단어의 개수만큼 차원이 지정됩니다. 사용되는 단어의 개수가 너무 많아서 지나치게 행렬이 희소해지면 사용이 불편하기 때문에, 필요하다면 벡터 임베딩 사이즈 또한 지정해줄 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"a4nh6x8o9KCP"},"source":["참고로 결과물이 희소행렬이기 때문에 평소에 사용되는 `numpy.ndarray`가 아닙니다. Scipy 모듈의 csr_matrix를 이용하는데 이는 아래 링크를 참고해주세요\n","+ [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)\n","+ [Scipy sparse matrix handling](https://lovit.github.io/nlp/machine%20learning/2018/04/09/sparse_mtarix_handling/)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535,"status":"ok","timestamp":1632395815088,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"sBuC_c-e9PHF","outputId":"eefe4215-a51b-460a-d6ab-a51163eb29fe"},"outputs":[{"data":{"text/plain":["scipy.sparse.csr.csr_matrix"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["type(sp_matrix)"]},{"cell_type":"code","execution_count":11,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:53:20.575499Z","start_time":"2021-09-15T06:53:20.562498Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1632395815713,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"PxHJP5HHfxFm","outputId":"5e51f435-3c18-4e0d-d5e5-4c804253e009"},"outputs":[{"data":{"text/plain":["(9606, 684272)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["sp_matrix.shape # (num_passage, num_vocab)"]},{"cell_type":"markdown","metadata":{"id":"TxSvTRPFiH0Z"},"source":["첫 번째 문장의 TF-IDF 벡터를 확인해볼까요?"]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:53:21.609083Z","start_time":"2021-09-15T06:53:20.577499Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2007,"status":"ok","timestamp":1632395819879,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"Nf0fNy11fzXY","outputId":"0ed450ad-e87e-43de-cda3-0e812a7dd863"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["            TF-IDF\n","비트코인      0.399592\n","인민 ##은행   0.213403\n","##은행 ##은  0.197794\n","##은행      0.153187\n","비트코인 거래   0.142268\n","비트코인 ##에  0.142268\n","금융        0.136443\n","인민        0.134331\n","금융 ##기    0.118108\n","##도 안     0.101123\n"]}],"source":["import pandas as pd\n","\n","df = pd.DataFrame(\n","    sp_matrix[0].T.todense(),\n","    index=vectorizer.get_feature_names(),\n","    columns=[\"TF-IDF\"]\n",")\n","df = df.sort_values(\"TF-IDF\", ascending=False)\n","print(df.head(10))"]},{"cell_type":"markdown","metadata":{"id":"IgjN_SF7iM_N"},"source":["### 💻 2. Query 임베딩하기"]},{"cell_type":"markdown","metadata":{"id":"YEdiT1W78X5y"},"source":["이제 Query 를 임베딩해봅시다. 아까 사용한 `vectorizer`를 이용하면 됩니다."]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:53:21.624082Z","start_time":"2021-09-15T06:53:21.611084Z"},"id":"sXSOfYisf5ad"},"outputs":[],"source":["sample_idx = random.choice(range(len(dataset[\"train\"])))\n","\n","query = dataset[\"train\"][sample_idx][\"question\"]\n","ground_truth = dataset[\"train\"][sample_idx][\"context\"]"]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:53:21.654082Z","start_time":"2021-09-15T06:53:21.626084Z"},"id":"dw0T5Drrf658"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n","  warnings.warn(\n"]}],"source":["query_vec = vectorizer.transform([query])"]},{"cell_type":"markdown","metadata":{"id":"MXpNKTYSia9D"},"source":["### 💻 3. Dot Product 를 통해 유사도 구하기\n","내적을 통해 주어진 Query 와 전체 Passage 사이의 유사도를 구해봅시다.\n","그리고 값을 내림차순으로 나열하여 높은 점수를 가진 Passage 들을 확인해봅시다."]},{"cell_type":"code","execution_count":15,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:54:25.265288Z","start_time":"2021-09-15T06:54:25.046289Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1632395825142,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"lLsck2Lyf_Vm","outputId":"3e940842-bc2e-4023-aaa1-cc6645d58468"},"outputs":[{"data":{"text/plain":["(1, 9606)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["result = query_vec * sp_matrix.T\n","result.shape"]},{"cell_type":"code","execution_count":16,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:54:26.190604Z","start_time":"2021-09-15T06:54:26.172592Z"},"id":"kLRrldUef8Cw"},"outputs":[],"source":["sorted_result = np.argsort(-result.data)\n","doc_scores = result.data[sorted_result]\n","doc_ids = result.indices[sorted_result]"]},{"cell_type":"code","execution_count":17,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:54:26.555129Z","start_time":"2021-09-15T06:54:26.541098Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1632395831462,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"kDYgaL3wgBC6","outputId":"bc810b50-e352-4391-da83-cc29b7b4dc88"},"outputs":[{"data":{"text/plain":["(array([0.21208908, 0.07221365, 0.0677442 , 0.05575468, 0.05302485]),\n"," array([8177,  310, 7488, 8662, 3096], dtype=int32))"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["k = 5\n","doc_scores[:k], doc_ids[:k]"]},{"cell_type":"markdown","metadata":{"id":"Pin40NMV91-l"},"source":["잘 뽑았는지 확인해봅시다."]},{"cell_type":"code","execution_count":18,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:54:27.343209Z","start_time":"2021-09-15T06:54:27.333696Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1632395832936,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"8e-OSr2tgCGt","outputId":"b018af21-6206-4404-ed18-867515da9686"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Search query]\n"," 구식 군인들의 월급인 쌀에 모래와 돌멩이가 들어가있던 사건을 말미암아 일어난 사태의 이름은? \n","\n","[Ground truth passage]\n","1882년 6월 민영익의 귀국 권고로 일시 귀국했다가 다시 되돌아갔다. 7월 23일 한성부에서 구식 군인들의 월급으로 주는 쌀에 모래와 돌멩이 및 썩은 쌀을 주자 여기에 반발한 구식 군인들에 의해 임오군란이 일어났는데, 그는 임오군란 사태 당시 행동을 삼가고 사태의 추이를 예의주시하고 있었다. 그러다가 그해 10월 13일 박영효, 김옥균 일행이 수신사(修信使) 겸 사죄사(辭罪使)로 하는 사절단(使節團)이 파견되자, 그는 박영효와 김옥균 일행이 도쿄에 방문했을 때 사절단의 통역을 맡아보았다. 수신사는 3개월간 일본의 각 기관을 시찰하고 일본의 여·야당 정치 지도자들과 만나 면담하고 각국 사절과도 폭넓게 접촉하여 의견을 교환했다. 한학을 배워 중국어와 일본어의 기초 실력이 있었던 그는 사절단의 통역을 맡아 활약했으며, 박영효 등이 귀국할 때 일본 유학을 마치고 박영효 일행과 함께 귀국했다. \n","\n","Top-1 passage with score 0.2121\n","1882년 6월 민영익의 귀국 권고로 일시 귀국했다가 다시 되돌아갔다. 7월 23일 한성부에서 구식 군인들의 월급으로 주는 쌀에 모래와 돌멩이 및 썩은 쌀을 주자 여기에 반발한 구식 군인들에 의해 임오군란이 일어났는데, 그는 임오군란 사태 당시 행동을 삼가고 사태의 추이를 예의주시하고 있었다. 그러다가 그해 10월 13일 박영효, 김옥균 일행이 수신사(修信使) 겸 사죄사(辭罪使)로 하는 사절단(使節團)이 파견되자, 그는 박영효와 김옥균 일행이 도쿄에 방문했을 때 사절단의 통역을 맡아보았다. 수신사는 3개월간 일본의 각 기관을 시찰하고 일본의 여·야당 정치 지도자들과 만나 면담하고 각국 사절과도 폭넓게 접촉하여 의견을 교환했다. 한학을 배워 중국어와 일본어의 기초 실력이 있었던 그는 사절단의 통역을 맡아 활약했으며, 박영효 등이 귀국할 때 일본 유학을 마치고 박영효 일행과 함께 귀국했다. \n","\n","Top-2 passage with score 0.0722\n","당시 백신시장에 개인용 백신은 무료배포가 많았던 시기라 개인사용자들에 한해서 1989년 부터 도스용 백신 소프트웨어인 V3+ 네오라는 백신을 무료로 제공하였다. 이후 V3+ 네오는 시그니처 수의 증가로 인해 당시 가장 보편적인 저장매체인 3.5인치 디스켓 2장이 필요하는 등 실제 이용이 매우 어렵고 제한되게 되었다. 결국 한동안 무료백신에 크게 신경을 쓰지 않던 안연구소는 알약 등의 경쟁 무료 제품의 확산을 막기 위해 빛자루 제품을 유료에서 무료로 바꾸고 V3 라이트라는 무료 제품을 연이어 출시한다. V3+ 네오는 V3 라이트 출시 이후 단종되었다. 안철수는 사업에 대해서 잘 모르는 상태에서 시작했기 때문에 처음 4년 간은 많은 고생을 했다. 당시 안철수연구소의 월급날은 매월 25일이었는데 월초부터 직원들의 월급 걱정을 해야 하는 지경이었고 자신이 월급을 받지 않고 직원들의 월급을 줄 때도 있었다. \n","\n","Top-3 passage with score 0.0677\n","사구(砂丘)는 바람에 의하여 모래가 이동하여 퇴적된 언덕이나 둑 모양의 모래 언덕이다. 내륙 사구는 고비 사막이나 사하라 사막과 같이 대륙 내부의 사막에 흔히 이루어진다. 사구는 한 장소에 고정되지 않고 독특한 모양을 유지하면서 바람이 부는 쪽으로 이동하는 경우가 많다. 사구 사이사이에는 기반암이나 자갈층이 드러난 경우도 있고, 넓은 지면이 모두 사구로 덮인 경우도 있다. 장애물이 바람에 가로놓여 있으면 바람그늘 쪽에는 풍속이 줄어들어 모래가 잘 쌓인다. 모래알이 장애물의 바람그늘 쪽에 쌓인 모래 위로 떨어지면 이동 속도가 줄어들어 모래가 계속 해서 집적하게 된다. 모래 더미가 원래의 장애물에 비하여 너무 크게 성장하면 다시 천천히 움직이면서 이동성 사구로 발전한다.한편, 해안 사구는 바닷물의 물결을 따라 바닷가에 밀려온 모래가 사빈으로 퇴적되었다가 다시 바다로부터 불어오는 바람에 실려가 사빈의 뒷쪽에 쌓여 생긴 것으로, 대개 해안선과 나란히 생긴다. 모래가 육지 쪽으로 너무 많이 날려가면 농경지가 묻히기 때문에, 이와 같은 해안의 주민들은 방풍림이나 방사림을 조성하여 모래의 이동을 막고 있다. \n","\n","Top-4 passage with score 0.0558\n","그리고 이러한 만민공동회 활동과 관련하여, 독립협회에서 만민공동회에 사주하여 결의한 헌의 6조에 배치되는 활동이 자주 나타났고, 그에 따라 황실에서는 독립협회를 탄압하려고 했다. 이러한 독립협회의 활동이 일본이나 미국에 유리한 조건을 조성해 주었고, 오히려 황실에서 추진하는 광무개혁이 일본이나 미국이 추진하는 경제적 침탈에 불리하게 작용하자, 그들은 황실의 만민공동회 탄압 계획을 번번이 저지하였다. 그들은 또한 독립협회 활동의 폭력화로 말미암아 무정부상태가 되는 일도 바라지 않았다. 그들이 생각하는 최악의 사태는 무정부상태로 말미암아 고종이 제2의 아관파천을 하는 일이었다. 미국과 일본은 그것을 막기 위해 독립협회에 대한 탄압은 억제하면서, 박영효 세력을 저지하는 한편 무력 진압을 양해하였다. 그 결과 독립협회의 활동으로 말미암아 오히려 외세 의존성을 심화하게 된다. \n","\n","Top-5 passage with score 0.0530\n","16개의 보 중에서 총 14개의 보를 2017년 11월 13일 수문을 개방했다. 이후 약 6개월이 지난 2018년 5월 4일 금강 세종보 상류는 수위가 낮아지면서 모래와 자갈로 이뤄진 작은 섬들이 드넓게 드러나기 시작했으며 좌안에는 모래가 30cm 이상 쌓이고 강물의 유속도 빨라지는 등 변화가 감지되었다. 현장 조사를 시행한 오준오 박사는 \"보 개방으로 실트층이 하류로 씻겨 내려가면서 자갈이 다시 드러났고, 모래가 쌓였다\"고 설명했다. 하지만 금강 하류의 백제보가 수문을 개방하지 않아 물빛이 세종보보다 탁했고 모래 대신 뻘만 가득하여 악취가 심한 등 이전과 차이가 없었다. 이는 낙동강도 마찬가지였다. 환경부 관계자는 \"보의 개방은 수질과 구조적 건강성, 생물학적 건강성 등 세 가지 측면에서 모두 긍정적 결과가 나타났다. 올해 말까지 개방한 보들에 대해 평가하고 처리 방안을 결정할 계획\"이라고 밝혔다. \n","\n"]}],"source":["print(\"[Search query]\\n\", query, \"\\n\")\n","\n","print(\"[Ground truth passage]\")\n","print(ground_truth, \"\\n\")\n","\n","for i in range(k):\n","    print(f\"Top-{i + 1} passage with score {doc_scores[i]:.4f}\")\n","    doc_id = doc_ids[i]\n","    print(corpus[doc_id], \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"DirOwPFOixwg"},"source":["Ground Truth 와 동일한 Passage 가 잘 나왔나요? 제법 성능이 나쁘지 않은걸 확인할 수 있네요.   \n","### ❓ 제시된 두 Tokenizer 를 모두 활용해서 결과를 비교해볼까요?\n","위에서 제시된 Hugginface Tokenizer 와 단순 띄어쓰기로 구분된 Tokenizer 는 많은 차이를 불러올까요? 직접 코드로 구현해봅시다."]},{"cell_type":"markdown","metadata":{"id":"Hl9vDzADcnPu"},"source":["### ❓ SparseRetrieval 코드를 class로 합쳐봅시다.\n","Sparse Retrieval 을 잘 구현하셨나요? 하지만 코드가 너무 흩어져있어서 다시 재사용하기 많이 어렵겠네요. 이 코드들을 다른 사람들도 잘 활용할 수 있도록 모듈화를 진행해봅시다."]},{"cell_type":"markdown","metadata":{"id":"34DcdPHglRIr"},"source":["❗ _Hint_   \n","Scratch 부터 짜는게 많이 어려우신가요?\n","\n","만들어야하는 기능들의 파이프라인을 나열하고 하나씩 모듈화하는 습관을 들이는 것이 좋습니다. 순서대로 생각해볼까요?\n","\n","1. 데이터를 불러옵니다.\n","2. TF-IDF 를 Fitting 한 후 Passage 를 Transform 합니다.\n","3. Query 를 Fitting 한 TF-IDF 를 통해 Transform 합니다.\n","4. Inner dot product 를 이용해 유사도를 구하고, 내림차순을 통해 유사한 Passage 를 Retrieval 합니다.\n","\n","위의 단계를 하나씩 함수로 구현한 후 class로 합치면 훨씬 쉬울 겁니다! 반드시 이 과정을 따르지 않으셔도 됩니다."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"Jr-IgCXWGysH"},"outputs":[],"source":["import json\n","\n","\n","class TfIdfRetrieval:\n","\n","    def __init__(self, tokenize_fn, data_path):\n","\n","        \"\"\"\n","        1. 여기서 Data를 불러올까요.\n","        \"\"\"\n","        with open(data_path, \"r\") as json_data:\n","            wiki_data = json.load(json_data)\n","            \n","        wiki_data_keys = list(wiki_data.keys())\n","        self.contexts = [wiki_data[key][\"text\"] for key in wiki_data_keys] # 여기 keys값의 text값을 받도록하기\n","        self.vectorizer = TfidfVectorizer(\n","            tokenizer=tokenize_fn,\n","            ngram_range=(1, 2),\n","            max_features=100000,\n","        )\n","\n","    def get_sparse_embedding(self):\n","\n","        \"\"\"\n","        2. 여기서 주어진 전체 passage들에 대해 TF-IDF를 .fit 해줍시다.\n","        \"\"\"\n","        self.vectorizer.fit(self.contexts)\n","        self.sp_matrix = self.vectorizer.transform(self.contexts)\n","\n","    def get_relevant_doc(self, query, k=1):\n","\n","        \"\"\"\n","        여기서\n","            3. Query를 받아서 TF-IDF에 Transform 시켜줍니다.\n","            4. 전체 Passage에 대한 유사도를 구한 후 상위 k개의 Passage를 반환합니다.\n","        \"\"\"\n","        query_vec = self.vectorizer.transform([query])\n","        result = query_vec * self.sp_matrix.T\n","        sorted_result = np.argsort(-result.data)\n","        doc_scores = result.data[sorted_result]\n","        doc_ids = result.indices[sorted_result]\n","        return doc_scores[:k], doc_ids[:k]\n","        \n","        "]},{"cell_type":"markdown","metadata":{"id":"l_2Vvx8BdzXw"},"source":["잘 구현하셨나요? 여러분들이 만든 클래스를 아래와 같이 활용하는데 성공하셨다면 마무리된 것입니다.\n"]},{"cell_type":"code","execution_count":31,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:54:39.464565Z","start_time":"2021-09-15T06:54:38.837869Z"},"id":"-W8Tl7osdyf7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/home/ubuntu/workspace/mission_venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n","  warnings.warn(\n"]}],"source":["tokenize_fn = lambda x: tokenizer.tokenize(x)\n","retriever = TfIdfRetrieval(tokenize_fn=tokenize_fn, data_path=\"../data/wikipedia_documents.json\")\n","\n","retriever.get_sparse_embedding()\n","query = \"미국의 대통령은 누구인가?\"\n","doc_score, doc_indices = retriever.get_relevant_doc(query, k=3)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"IXorfdV1hHGH"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Search Query] 미국의 대통령은 누구인가?\n","Top-1th Passage (Index 26553)\n","('미국의 대통령 가족(First Family of the United States)은 미국의 국가 원수이자 정부 수반인 미국의 대통령 '\n"," '가족을 일컫는 비공식적인 명칭이다. 대통령 가족은 대통령과 미국의 대통령 부인, 그리고 그들의 자녀들로 구성된다. 그러나, 대통령과 '\n"," '대통령 부인의 가까운 친척들인 부모, 손자, 의붓자식 등이 백악관 단지의 대통령 관저에 거주할 경우에는 그들도 대통령 가족에 포함될 수 '\n"," '있다.\\n'\n"," '\\n'\n"," '미국에서 대중 매체나 특히, 백악관 기자단에서 가장 자주 사용하는 \"대통령 가족\"(First Family)이라는 용어는 일반적으로 '\n"," '대통령의 직계 가족을 가리키는 말이다. 개별적으로, 대통령 가족의 각 구성원은 미국 비밀 경호국에서 비밀 경호 코드네임으로 지정된다. '\n"," '특수 요원들이 사용하는 이러한 코드네임은 간결성, 명확성, 전통 등을 위할 뿐만 아니라 대통령 가족의 지속적인 보호를 위해 특별하게 '\n"," '식별된다.\\n'\n"," '\\n'\n"," '수 대에 걸쳐 대통령 가족을 배출한 가문은 미국의 명문 대통령 가문으로 불린다.')\n","Top-2th Passage (Index 30424)\n","('2000년 개헌에 따라 핀란드 대통령은 권한은 많이 축소됐다. 핀란드 대통령은 내각과 함께 대외 정책을 이끈하다. 하지만 유럽정책은 '\n"," '총리의 소관이다. 대통령은 국내 문제에 대한 권한이 거의 없다. 대통령에게 의회 해산권이 있지만, 총리의 요청에 따라 해산할 수 있다. '\n"," '또 대통령은 법안에 대한 인준을 결정할 수 없다. 단지 대통령은 법안을 의회로 다시 돌려보낼 수 있고, 의회는 재의결을 통해 대통령의 '\n"," '서명없이 법률을 공표할 수 있다. 대통령이 임명할 수 있는 공직의 수가 줄어 들기는 했지만, 군장성과 판사의 임명권은 여전히 대통령에게 '\n"," '있다. 대통령은 핀란드 방위군 통수권자이며, 사면권을 가지고 있다.\\n'\n"," '    \\n'\n"," '\\n'\n"," '2000년 개헌에 따른 권한 축소 이후, 대통령은 상징적 지도자로 받아들여지고 있다.')\n","Top-3th Passage (Index 26978)\n","('베피콜롬보\\n'\n"," '베피콜롬보는 수성 탐사 계획 중 하나로 ESA와 JAXA가 공동으로 계획했다. 소형 탐사선 2기를 보유하고 있으며, 유럽(MPO)과 '\n"," '일본MMO)에서 각각 한 기씩 제공했으며, 또한 한 기는 사진을 찍고, 다른 한 기는 자기장을 연구하는 등 역할이 확실히 구별되어 '\n"," '있다. \\n'\n"," '\\n'\n"," '#태양 성운, 행성계에 있어서, 수성에 대해 연구해야 할 것은 무엇인가?\\n'\n"," '#왜 수성의 밀도는 다른 지구형 행성보다 높은가?\\n'\n"," '#수성의 핵은 액체인가? 고체인가?\\n'\n"," '#오늘날도 수성 구조는 활동적인가?\\n'\n"," '#금성과 화성, 달도 가지고 있지 못 한 작은 행성이 왜 자기장을 가지고 있는가?\\n'\n"," '#수성의 주 성분이 철임에도, 분광 관측으로는 발견되지 않았던 이유는 무엇인가?\\n'\n"," '#극점의 영구 동토에는 황 혹은 얼음이 존재하는가?\\n'\n"," '#외기권의 형성 원리는 무엇인가?\\n'\n"," '#이온층이 없는데도, 자기장과 태양풍이 어떻게 상호 작용을 하는가?\\n'\n"," '#수성의 자화(磁化)된 환경이 지구에서 관측되는 오로라, 밴 앨랜대, 자기 폭풍 등이 존재한다는 것을 암시하는가?\\n'\n"," '#공간의 왜곡으로 인한 수성의 근일점 변화가 일반상대성이론에 근거한 결과의 오차값을 더 줄일 수 있는가\\n'\n"," '\\n'\n"," '매리너 10호나 메신저와 같이, 베피콜롬보는 금성과 지구에서 플라이바이를 사용할 예정이다. 특히, 태양 에너지 추진을 이용하여 달, '\n"," '금성을 지나 수성에 느린 속도로 도달 할 전망이다. 이런 기술은 태양 중력의 영향을 최소화하여 수성에 접근하기 위해서는 필수적이다\\n'\n"," '\\n'\n"," '베피콜롬보는 2018년 10월 경에 발사 되어, 2025년 12월 5일, 수성 궤도로 진입 할 예정이다. 그 후, 2년동안 수성에 대한 '\n"," '정보를 모으고 연구를 행할 것이다.')\n"]}],"source":["print(f\"[Search Query] {query}\")\n","\n","for i, idx in enumerate(doc_indices):\n","    print(f\"Top-{i + 1}th Passage (Index {idx})\")\n","    pprint(retriever.contexts[idx])"]},{"cell_type":"markdown","metadata":{"id":"SHOE4jZqhXRs"},"source":["직접 만든 코드에 다음과 같은 추가 사항들을 고려해봅시다.   \n","#### ➕추가 과제: 다양한 기능 추가하기\n","+ 현재 코드가 **어떻게 동작하고 있는지** 궁금하지 않으신가요? 가령, 코드가 돌고는 있는데 대체 어떤 메소드를 수행 중인지, 아니면 시간이 얼마나 걸리는지 등 추가적인 정보를 Logger 에 기록하거나 Prompt 에 찍는 방향으로 더 추가해보세요 !\n","+ 위에서 시간을 출력하는 코드를 짜보셨다면, 이제 fitting 시간이 적지 않음을 확인할 수 있었습니다. 그리고 passage 가 자주 변경되는 것이 아니라면, 같은 기법을 사용해서 **매번 fitting 을 하는 것은 아주 비효율적**입니다. 임베딩된 passage를 따로 **저장해두고 불러와서 사용하면** 더 효율적이지 않을까요? 이 임베딩들을 `.bin` 파일로 저장하고, 만약 `.bin` 파일이 있다면 TfidfVectorizer 가 fitting 하지 않고, 이 `.bin` 파일을 불러오는 방향으로 코드를 추가해봅시다.\n","+ 예외 케이스가 있지 않을까요? **query가 `str` 1개가 아니라 2개 이상인 `List[str]`로 주어진 경우에는 어떻게 해야할까요?** 이 상황은 멀리 있지 않고 여러분들이 대회에서 inference 할 때도 필요한 코드입니다. 단순히 반복문을 돌릴 수 있지만, 우리는 행렬곱을 이용하고 있기 때문에 만약 query 가 여러 개면 이 행렬곱의 장점을 이용할 수 있을 것 같습니다.\n","    + 한 개의 query(`str`) 에 대해 유사한 passage 를 구하는 함수와\n","    + 여러 개의 query(`list`) 에 대해 유사한 passage 를 구하는 함수\n","\n","  두 가지를 만들어봅시다. 그리고 `retrieve` 라는 함수를 만들어서 query 가 한 개인지 다수인지 체크한 후 각각의 함수를 사용해서 유사한 passage 를 찾도록 수정해봅시다.\n","+ 또 다른 예외케이스는 `TfidfVectorizer` 에서 생길 수 있습니다. 가령 Passage 에서 한 번도 보지 못한 단어로만 구성된 query 를 입력했다면, TF-IDF 의 특성상 이 단어는 0 으로만 임베딩될 것입니다. 전체 벡터가 0이 되면 어떻게 처리해야할까요? `assert` 를 활용해보세요!\n","+ 이 메소드는 어떤 parameters를 받아오고 어떤 기능을 하는지 docstring을 추가해봅시다.\n","\n","\n","요구사항이 너무 많나요? 원래 인생이 그렇습니다.\n","\n","_Sparse Retrieval 과제는 두 가지 (기존과 추가 과제) 모두 예시 코드가 금요일 (10/15)제공됩니다._"]},{"cell_type":"markdown","metadata":{"id":"zpoTleVJjp5x"},"source":["## 💻 Ⅱ. Dense Retriever (BERT) 학습 시키기\n","\n","이번에는 BERT 를 불러오고 학습시키는 과정을 거쳐봅시다. 시작하기 전에 어떤 과정을 거쳐야할 지 생각해봅시다.\n","1. 데이터셋 준비\n","2. 모델 준비\n","3. 학습하기 \n","\n"]},{"cell_type":"markdown","metadata":{"id":"HmAIDfEbeENm"},"source":["### 💻 1. 데이터셋 준비하기\n","위에서 불러온 `datasets`를 이용해 데이터를 불러왔습니다. 하지만 이번 과제에서 passage encoder 가 학습되는 방식은 주어진 query/question에 적합한 passage 를 찾아오는 과정이 필요한데, 이 때 올바른 데이터만 이용해서 학습하는 것이 아니라, 올바르지 않은 passage 또한 학습해보는 과정을 거쳐야합니다. 이를 in-batch negative 라고 부르는데 관련된 내용은 기계독해 강의와 아래 논문을 참고해보세요.\n","+ [Dense Passage Retrieval](https://arxiv.org/abs/2004.04906)"]},{"cell_type":"markdown","metadata":{"id":"N-bKwkxTpoje"},"source":["#### 💻 Training Dataset 준비하기 (question, passage pairs)\n","\n","실습 시간을 단축시키기 위해 일부 데이터만 활용해봅시다.\n","\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:56:49.543616Z","start_time":"2021-09-15T06:56:49.543616Z"},"id":"E_FQ1kcazxge"},"outputs":[],"source":["sample_idx = np.random.choice(range(len(dataset[\"train\"])), 20)\n","training_dataset = dataset[\"train\"][sample_idx]"]},{"cell_type":"markdown","metadata":{"id":"ALNnnBJTxeU4"},"source":["#### 💻 Negative sampling 을 위한 negative sample 들을 샘플링\n","\n","주어진 query/question 에 해당하지 않는 지문들을 뽑아서 훈련데이터로 넣어줍시다. "]},{"cell_type":"code","execution_count":34,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:56:49.545616Z","start_time":"2021-09-15T06:56:49.545616Z"},"id":"LPomXJ1Afc6l"},"outputs":[],"source":["# In-batch Negatvie로 사용할 데이터 생성\n","num_neg = 2\n","\n","corpus = np.array(corpus)\n","p_with_neg = []\n","\n","for c in training_dataset[\"context\"]:\n","    \n","    while True:\n","        neg_idxs = np.random.randint(len(corpus), size=num_neg)\n","\n","        if not c in corpus[neg_idxs]:\n","            p_neg = corpus[neg_idxs]\n","\n","            p_with_neg.append(c)\n","            p_with_neg.extend(p_neg)\n","            break"]},{"cell_type":"markdown","metadata":{"id":"ir_hYkQ5fBro"},"source":["주어진 질문에 알맞는 지문과 올바르지 않는 지문을 모두 살펴봅시다."]},{"cell_type":"code","execution_count":35,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T06:56:49.546616Z","start_time":"2021-09-15T06:56:49.546616Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1632397097228,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"wbGW7PRJ7Yv5","outputId":"7bc3b3ac-5f88-4c0f-fa07-76bf21d9b148"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Query Given]\n","'문제는 나랏법 자체보다는 법을 적용하고 옹호하는 데 있었다고 묘사한 사학자는?'\n","\n","[Positive context]\n","('전원 공동체, 특히 그 중에서도 잉글랜드 동남부는 농노제의 작동과 지역 장원 재판소의 세금 징수를 불만스러워했다. 특히 재판소를 운영하는 '\n"," '영주들이 곧 원성을 사는 노동 조례나 왕실에서 제정한 법의 현장 집행자로 기능하는 경우가 잦았기 때문에 불만은 가중되었다. 촌락의 엘리트 '\n"," '계층 다수는 지방정부의 역할을 맡는 것을 거부했고, 재판소의 활동을 방해하기 시작했다. 재판소에 의해 몰수된 가축들은 그 주인들에 의해 '\n"," '‘해방’되었고, 법관들은 폭행을 당했다. 일부는 전통적인 법을 존중하나 런던에서 내려오는 증오받는 중앙 법률에서는 분리된, 독립적인 촌락 '\n"," '공동체의 탄생을 지지하기 시작했다. 사학자 미리 루빈은 이 상황을, “문제는 나랏법 그 자체라기보다, 그 법을 적용하고 옹호하는 데 '\n"," '있었다”고 묘사한다.')\n","\n","[Negative context]\n","'2018년 1월 26일 화재 사고 발생 직후 경찰수사본부(본부장 진정무 경남지방청2부장), 검찰 수사팀(수사지휘 총괄 창원지검 김홍창 차장검사, 수사팀장 박현철 밀양지청장), 수사지원팀(팀장 창원지검 김완규 형사2부장)을 구성하여 협조체제가 구축되었다. 2018년 2월 10일 효성의료재단세종병원을 운영한 (의)효성의료재단 이사장 손경철, 효성의료재단세종병원 총무과장(소방안전관리자) B를 구속하였다. 2018년 2월 23일에는 세종병원의 행정이사 C를 구속하였으며, 3월 6일 재단 이사장 손경철(업무상과실치사상, 의료법위반, 건축법위반, 위계공무집행방해)과 세종병원 총무과장 B(업무상과실치사상)를 구속기소하였다. 2018년 3월 15일에는 세종병원 행정이사 C(업무상과실치사상, 의료법위반)를 구속기소하였으며, 세종병원 병원장 D(업무상과실치사상, 의료법위반), (의)효성의료재단 법인(의료법위반, 약사법위반, 건축법위반), ○○보건소 공무원 F(허위공문서작성·동행사), ○○보건소 전 공무원 G(허위공문서작성·동행사)를 불구속 기소, 대진의사 H(의료법위반), I(의료법위반), J(의료법위반), (의)효성의료재단세종요양병원 전 의사 K(약사법위반), 세종요양병원 간호사 L(약사법위반), N발전기 운영자 M(위계공무집행방해방조)를 약식기소했다.'\n","'중국은 한정 상무위원을 시진핑 주석의 특별대표 자격으로 파견했다. 문재인은 한정과 8일 회담을 가졌으며 북한과의 대화를 지속시켜 북핵 문제 해결을 위한 대화로 연결될 수 있도록 양국이 긴밀히 협력해 나갈 것을 촉구했다. 한편, 중국에 진출한 한국 기업의 편의 확대와 중국 관광객 교류 활성화도 함께 요청했다. 9일에는 아베가 전용기를 타고 양양국제공항을 통해 방한했다. 이후 평창에서 문재인과 정상회담을 가졌는데 문재인은 역사를 직시하면서 지혜와 힘을 합쳐 미래지향적 협력을 추진하고자 한다며 \"양국이 마음이 통하는 진정한 친구가 되길 진정으로 바란다\"고 말했다. 이에 아베는 북한 문제에 대해 한미일 간 협력관계를 재확인하면서 \"일본과 한국의 미래지향적이고 새로운 관계 구축을 위해서 솔직하게 의견을 나눴으면 한다\"고 화답했다. 하지만 아베가 한미 군사훈련을 연기할 단계가 아니라며 예정대로 진행하는 것이 중요하다고 말하자 문재인이 주권의 문제이고 내정에 관한 문제라며 직접 거론하는 것은 곤란하다고 맞받아쳐 견해차를 드러내기도 했다. 일본 정부는 다시 한미 연합훈련은 한국의 내정 문제로 끝나는 문제가 아니라며 한미일 공조의 유지를 다시 한 번 강조했다.'\n"]}],"source":["print(\"[Query Given]\")\n","pprint(training_dataset[\"question\"][0])\n","\n","print(\"\\n[Positive context]\")\n","pprint(p_with_neg[0])\n","\n","print(\"\\n[Negative context]\")\n","pprint(p_with_neg[1])\n","pprint(p_with_neg[2])"]},{"cell_type":"markdown","metadata":{"id":"6jW0gXtJ-_nf"},"source":["처리한 데이터를 `torch`가 처리할 수 있게 `DataLoader`로 넘겨주는 작업을 해봅시다. 기본적으로 Huggingface Pretrained 모델이 `input_ids`, `attention_mask`, `token_type_ids`를 받아주니, 이 3가지를 넣어주도록 합시다."]},{"cell_type":"code","execution_count":38,"metadata":{"id":"jiacVxXFeBbK"},"outputs":[],"source":["from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n","\n","q_seqs = tokenizer(\n","    training_dataset[\"question\"],\n","    padding=\"max_length\",\n","    truncation=True,\n","    return_tensors=\"pt\"\n",")\n","p_seqs = tokenizer(\n","    p_with_neg,\n","    padding=\"max_length\",\n","    truncation=True,\n","    return_tensors=\"pt\"\n",")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([20, 512])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["q_seqs[\"input_ids\"].size()"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([20, 3, 512])"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["p_seqs[\"input_ids\"].size()"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1632397097228,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"dvzIayy79Mdy","outputId":"02e08862-b73f-4bd3-c629-534c8ff88298"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([20, 3, 512]) 512\n"]}],"source":["max_len = p_seqs[\"input_ids\"].size(-1)\n","p_seqs[\"input_ids\"] = p_seqs[\"input_ids\"].view(-1, num_neg + 1, max_len)\n","p_seqs[\"attention_mask\"] = p_seqs[\"attention_mask\"].view(-1, num_neg + 1, max_len)\n","p_seqs[\"token_type_ids\"] = p_seqs[\"token_type_ids\"].view(-1, num_neg + 1, max_len)\n","\n","print(p_seqs[\"input_ids\"].size(), max_len)  # (num_example, pos + neg, max_len)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"bAplp66Pkayy"},"outputs":[],"source":["train_dataset = TensorDataset(\n","    p_seqs[\"input_ids\"], p_seqs[\"attention_mask\"], p_seqs[\"token_type_ids\"], \n","    q_seqs[\"input_ids\"], q_seqs[\"attention_mask\"], q_seqs[\"token_type_ids\"]\n",")"]},{"cell_type":"markdown","metadata":{"id":"JwMvVH1e3h99"},"source":["### 💻 2. BERT encoder 학습시키기\n","1. BERT 모델을 구성한 후\n","2. Passage 를 임베딩하는 `p_encoder`와 Query/Question 을 임베딩하는 `q_encoder` 를 각각 선언해줍니다.\n","3. 두 모델을 학습시킵니다."]},{"cell_type":"code","execution_count":48,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T08:06:32.340866Z","start_time":"2021-09-15T08:06:32.327858Z"},"id":"oKKkTlh_l5VL"},"outputs":[],"source":["class BertEncoder(BertPreTrainedModel):\n","\n","    def __init__(self, config):\n","        super(BertEncoder, self).__init__(config)\n","\n","        self.bert = BertModel(config)\n","        self.init_weights()\n","      \n","      \n","    def forward(self,\n","            input_ids, \n","            attention_mask=None,\n","            token_type_ids=None\n","        ): \n","  \n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids\n","        )\n","        \n","        pooled_output = outputs[1]\n","        return pooled_output"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12987,"status":"ok","timestamp":1632397110212,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"wnO1b30SomBP","outputId":"635dec4b-33c2-4026-8fef-a6fa8f150829"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50e1eb432e7744b19fdd117a9f4faace","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445025130.0, style=ProgressStyle(descri…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# Pre-train된 모델을 사용해줍니다. 위에서 사용한 `model_checkpoint`를 재활용합니다.\n","p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n","q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n","\n","if torch.cuda.is_available():\n","    p_encoder.cuda()\n","    q_encoder.cuda()"]},{"cell_type":"markdown","metadata":{"id":"f3Dgo8U997HD"},"source":["`train` 함수를 정의한 후 `p_encoder`과 `q_encoder`를 학습시켜봅시다.\n"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"VAb7NpUc8YRo"},"outputs":[],"source":["def train(args, num_neg, dataset, p_encoder, q_encoder):\n","    batch_size = args.per_device_train_batch_size\n","  \n","    # Dataloader\n","    train_dataloader = DataLoader(dataset, batch_size=batch_size)\n","\n","    # Optimizer\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n","        {\"params\": [p for n, p in p_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","        {\"params\": [p for n, p in q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n","        {\"params\": [p for n, p in q_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=args.learning_rate,\n","        eps=args.adam_epsilon\n","    )\n","    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=args.warmup_steps,\n","        num_training_steps=t_total\n","    )\n","\n","    # Start training!\n","    global_step = 0\n","\n","    p_encoder.zero_grad()\n","    q_encoder.zero_grad()\n","    torch.cuda.empty_cache()\n","\n","    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n","    for _ in train_iterator:\n","\n","        # epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n","        with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n","            for batch in tepoch:\n","\n","                p_encoder.train()\n","                q_encoder.train()\n","        \n","                targets = torch.zeros(batch_size).long() # positive example은 전부 첫 번째에 위치하므로\n","                targets = targets.to(args.device)\n","\n","                p_inputs = {\n","                    \"input_ids\": batch[0].view(batch_size * (num_neg + 1), -1).to(args.device),\n","                    \"attention_mask\": batch[1].view(batch_size * (num_neg + 1), -1).to(args.device),\n","                    \"token_type_ids\": batch[2].view(batch_size * (num_neg + 1), -1).to(args.device)\n","                }\n","        \n","                q_inputs = {\n","                    \"input_ids\": batch[3].to(args.device),\n","                    \"attention_mask\": batch[4].to(args.device),\n","                    \"token_type_ids\": batch[5].to(args.device)\n","                }\n","\n","                del batch\n","                torch.cuda.empty_cache()\n","                # (batch_size * (num_neg + 1), emb_dim)\n","                p_outputs = p_encoder(**p_inputs)\n","                # (batch_size, emb_dim)  \n","                q_outputs = q_encoder(**q_inputs)\n","\n","                # Calculate similarity score & loss\n","                p_outputs = p_outputs.view(batch_size, -1, num_neg + 1)\n","                q_outputs = q_outputs.view(batch_size, 1, -1)\n","\n","                # (batch_size, num_neg + 1)\n","                sim_scores = torch.bmm(q_outputs, p_outputs).squeeze()  \n","                sim_scores = sim_scores.view(batch_size, -1)\n","                sim_scores = F.log_softmax(sim_scores, dim=1)\n","\n","                loss = F.nll_loss(sim_scores, targets)\n","                tepoch.set_postfix(loss=f\"{str(loss.item())}\")\n","\n","                loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","\n","                q_encoder.zero_grad()\n","                p_encoder.zero_grad()\n","\n","                global_step += 1\n","\n","                torch.cuda.empty_cache()\n","                del p_inputs, q_inputs\n","\n","    return p_encoder, q_encoder"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"ICSJoJrUDGZ5"},"outputs":[],"source":["args = TrainingArguments(\n","    output_dir=\"dense_retireval\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=2, # 아슬아슬합니다. 작게 쓰세요 !\n","    per_device_eval_batch_size=2,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n",")"]},{"cell_type":"markdown","metadata":{"id":"I5h7_-aRA9dm"},"source":["_혹시 CUDA 메모리 에러가 뜬다면 passage encoder 와 query encoder 를 나누지 말고 하나로 학습해보세요. `batch_size`도 변경해보세요._"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41816,"status":"ok","timestamp":1632396383943,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"E8a7ww3WgsaZ","outputId":"fbbd90b3-b569-450c-8054-692333666768"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:04<00:00,  2.01batch/s, loss=0.0]\n","100%|██████████| 10/10 [00:05<00:00,  1.98batch/s, loss=0.0]\n","Epoch: 100%|██████████| 2/2 [00:10<00:00,  5.02s/it]\n"]}],"source":["p_encoder, q_encoder = train(args, num_neg, train_dataset, p_encoder, q_encoder)"]},{"cell_type":"markdown","metadata":{"id":"BGOw-k7Ln85t"},"source":["### 💻 3. 검증셋에 있는 Query 에 대해 passage-retrieval 해보기\n","이제 처음 보는 검증셋에 있는 Query 와 passage 에 대해서도 잘 작동하는지 확인해봅시다. 아래와 같은 순서로 작동해야겠죠?\n","1. 검증셋을 불러온다.\n","2. 검증셋의 query 와 passage 를 임베딩시킨다.\n","3. 유사도를 통해 유사한 주어진 query 에 맞는 passage 를 찾는다."]},{"cell_type":"markdown","metadata":{"id":"FZA5V6tEpuUV"},"source":["#### 💻 검증셋 불러오기"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":505,"status":"ok","timestamp":1632397110710,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"NouB9uBcTaws","outputId":"d20d885c-d7cf-481f-f5fa-66b3952236b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Selected Query]\n","'SKY가 휴대전화 CM에서 푸시캣 돌스의 노래와 함꼐 춘 춤은?'\n","[Ground Truth]\n","('2005년 9월 13일 푸시캣 돌스의 첫 번째 정규 음반 PCD가 발매됐다. 이 앨범은 그들이 활동했던 댄스팀 스타일의 댄스팝 음악들과, '\n"," '트리뷰트, 커버곡들로 구성되어 있다. 이 앨범은 뉴질랜드에서 1위를 차지했고, 캐나다, 네덜란드, 미국에서 TOP 5에 이름을 올렸으며, '\n"," '영국, 오스트리아, 독일, 스위스, 아일랜드에서 10위까지 올라갔다. PCD는 전 세계적으로 900만 장 이상의 판매고를 올렸다. 첫 '\n"," \"싱글 'Don't Cha'는 영국, 오스트레일리아, 캐나다 등의 나라에서 1위에 올랐고, 빌보드 핫 100 차트 2위에 올랐다. 또한 이 \"\n"," \"노래는 한국의 휴대전화 기기 제조사 SKY의 휴대전화 CM송으로 쓰여, CM 속 모델들이 추는 춤 이름인 '맷돌춤'의 배경음악으로 \"\n"," '유행하기도 하였다.')\n"]}],"source":["valid_corpus = list(set([example[\"context\"] for example in dataset[\"validation\"]]))[:10]\n","\n","sample_idx = random.choice(range(len(dataset[\"validation\"])))\n","query = dataset[\"validation\"][sample_idx][\"question\"]\n","ground_truth = dataset[\"validation\"][sample_idx][\"context\"]\n","\n","if not ground_truth in valid_corpus:\n","    valid_corpus.append(ground_truth)\n","\n","print(f\"[Selected Query]\")\n","pprint(query)\n","\n","print(f\"[Ground Truth]\")\n","pprint(ground_truth)"]},{"cell_type":"markdown","metadata":{"id":"05D8GzFrJhHO"},"source":["#### 💻 앞서 학습한 passage encoder, question encoder 을 이용해 dense embedding 생성하기"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1358,"status":"ok","timestamp":1632397112067,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"YufA_ayPJBRg","outputId":"cd5720b6-46c9-4da6-d5dc-d480868348e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([11, 768]) torch.Size([1, 768])\n"]}],"source":["with torch.no_grad():\n","    p_encoder.eval()\n","    q_encoder.eval()\n","\n","    q_seqs_val = tokenizer(\n","        [query],\n","        padding=\"max_length\",\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","    q_emb = q_encoder(**q_seqs_val).to(\"cpu\")  # (num_query, emb_dim)\n","\n","    p_embs = []\n","    for p in valid_corpus:\n","        p = tokenizer(\n","            p,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        ).to(\"cuda\")\n","        p_emb = p_encoder(**p).to(\"cpu\").numpy()\n","        p_embs.append(p_emb)\n","\n","p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n","print(p_embs.size(), q_emb.size())"]},{"cell_type":"markdown","metadata":{"id":"pOHHak7WS1ko"},"source":["#### 💻 Dot product를 통해 유사도 구하기"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1632397112067,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"xn5Cx5JkKZJB","outputId":"84d37434-bfe5-4a6f-d160-d0ca72d65bcd"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 11])\n","tensor([[107.5853, 138.5627, 128.6359, 102.0809, 119.4673, 120.3933, 129.9795,\n","         119.8215, 134.0216, 142.6412, 155.6174]])\n","tensor([10,  9,  1,  8,  6,  2,  5,  7,  4,  0,  3])\n"]}],"source":["dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n","print(dot_prod_scores.size())\n","\n","rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n","print(dot_prod_scores)\n","print(rank)"]},{"cell_type":"markdown","metadata":{"id":"Oq2Oiv8MKVS6"},"source":["#### 💻 Top-5개의 passage를 retrieve 하고 ground truth와 비교하기"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1632397112068,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"WaStRXYdJ-wI","outputId":"9d93531f-8e65-43c7-dfdc-a1184963362f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Search query]\n"," SKY가 휴대전화 CM에서 푸시캣 돌스의 노래와 함꼐 춘 춤은? \n","\n","[Ground truth passage]\n","2005년 9월 13일 푸시캣 돌스의 첫 번째 정규 음반 PCD가 발매됐다. 이 앨범은 그들이 활동했던 댄스팀 스타일의 댄스팝 음악들과, 트리뷰트, 커버곡들로 구성되어 있다. 이 앨범은 뉴질랜드에서 1위를 차지했고, 캐나다, 네덜란드, 미국에서 TOP 5에 이름을 올렸으며, 영국, 오스트리아, 독일, 스위스, 아일랜드에서 10위까지 올라갔다. PCD는 전 세계적으로 900만 장 이상의 판매고를 올렸다. 첫 싱글 'Don't Cha'는 영국, 오스트레일리아, 캐나다 등의 나라에서 1위에 올랐고, 빌보드 핫 100 차트 2위에 올랐다. 또한 이 노래는 한국의 휴대전화 기기 제조사 SKY의 휴대전화 CM송으로 쓰여, CM 속 모델들이 추는 춤 이름인 '맷돌춤'의 배경음악으로 유행하기도 하였다. \n","\n","Top-1 passage with score 155.6173858642578:.4f\n","('2005년 9월 13일 푸시캣 돌스의 첫 번째 정규 음반 PCD가 발매됐다. 이 앨범은 그들이 활동했던 댄스팀 스타일의 댄스팝 음악들과, '\n"," '트리뷰트, 커버곡들로 구성되어 있다. 이 앨범은 뉴질랜드에서 1위를 차지했고, 캐나다, 네덜란드, 미국에서 TOP 5에 이름을 올렸으며, '\n"," '영국, 오스트리아, 독일, 스위스, 아일랜드에서 10위까지 올라갔다. PCD는 전 세계적으로 900만 장 이상의 판매고를 올렸다. 첫 '\n"," \"싱글 'Don't Cha'는 영국, 오스트레일리아, 캐나다 등의 나라에서 1위에 올랐고, 빌보드 핫 100 차트 2위에 올랐다. 또한 이 \"\n"," \"노래는 한국의 휴대전화 기기 제조사 SKY의 휴대전화 CM송으로 쓰여, CM 속 모델들이 추는 춤 이름인 '맷돌춤'의 배경음악으로 \"\n"," '유행하기도 하였다.')\n","Top-2 passage with score 142.6412353515625:.4f\n","('2006년 11월 3일에 열린 닌텐도 월드에서는 2007년에 발매될 예정이라는 발표와 함께 게임의 영상이 공개되었다. 2007년 4월 '\n"," '6일에는 일본의 공식 웹사이트에서 티저 영상을 공개하였다. 이어서 2007년 4월 13일에는 캐릭터 프로필과 스크린샷이 포함된 두 번째 '\n"," '트레일러가 공개되었다. 캡콤의 기획 및 조사 디렉터 크리스티안 스벤슨은 게임이 480의 순차 주사 방식과 16:9의 와이드스크린을 지원할 '\n"," '것이라고 언급하였다. 《바이오하자드 4 위 에디션》에도 특전 영상으로 트레일러가 포함되어 있는데, 여기에 포함된 영상은 오리지널의 양관과 '\n"," '라쿤 시의 일부 지역을 보여주었다. 2007년 7월 11일의 E3에서 닌텐도 측은 총 악세사리인 Wii 재퍼를 게임에서 사용할 수 있다고 '\n"," '언급하였다.')\n","Top-3 passage with score 138.56272888183594:.4f\n","('타율은 지난 시즌에 비해 떨어졌으나, 팀의 간판선수 앤드류 맥커친이 부진할 때 4번타자로 나서는 등 확실하게 주전선수로써 입지를 '\n"," '굳혀나갔다. 2016년 9월 26일 워싱턴 내셔널스와의 경기에서 벤치클리어링에 휘말리기도 하였다. 워싱턴 간판타자 브라이스 하퍼가 3루로 '\n"," '슬라이딩 해 들어갈 때 당시 3루수였던 강정호가 태크를 하는 과정에서 하퍼가 부상을 입으면서 양 팀간의 신경전이 시작되었고 다음 이닝에서 '\n"," '워싱턴 투수가 강정호에게 머리쪽으로 위협구를 던지면서 투수는 퇴장당했다. 이에 대해 피츠버그 프란시스코 서벨리와 션 로드리게스 등이 '\n"," '강정호를 보호히기 위해 전면전에 나섰고 결국 양팀 선수들이 모두 경기장으로 뛰쳐나오는 사태가 벌어졌다. 이 경기에서 강정호는 아시아인 '\n"," '최초로 20홈런을 기록하는 등 큰 활약을 해주었다. 이 시즌에는 팀 중심타자로써 기대에 부응하는 모습을 보여줬다.')\n","Top-4 passage with score 134.02159118652344:.4f\n","('사(伺, 자세한 상(相: 성질, 모습, 자성)을 분별함, 세밀한 성질, 세밀한 움직임, 산스크리트어: vicara, vitarkah, '\n"," '팔리어: vicāra, 영어: discernment, discursiveness, analysis, sustained '\n"," 'application, sustained thinking, selectiveness, subtle discernment, subtlety '\n"," 'of the mind)는, 능히 의언(意言: 뜻의 말, 마음속의 단어)의 분별(分別)을 사찰(伺察: 정밀하게 살펴봄)할 수 있는 '\n"," '사(思)와 혜(慧)의 마음작용의 차별(差別)로서의, 심세(心細) 즉 마음의 세밀한 성질을 자성으로 하는 마음작용, 즉 마음과 상응하는 '\n"," '법이다.')\n","Top-5 passage with score 129.9795379638672:.4f\n","('소토마요르는 실내 시즌 동안에 1996년에 좋은 시작을 가졌으나, 실외 시즌 동안에 부상으로 시달리고 말았다. 1996년 애틀랜타 '\n"," '올림픽에서 자신의 올림픽 타이틀을 유지하려는 시도를 하였다. 7월 26일 시합에 나가는 데 성공적으로 합격하였으나, 이틀 후에는 자신의 '\n"," '첫 시도에서 제거하면서 2.25m(7 피트 4.58 인치)의 개막 넘기 만을 관리할 수 있었다. 그러고나서 다음 높이 2.29m(7 피트 '\n"," '6.16 인치)를 통과하다가 2.32m(7 인치 7에 4분의 1 인치)의 3개의 시도들에서 실패하여, 자신의 2.25m 제거는 그를 '\n"," '11위에 머물게 하고 말았다. 결국 미국의 찰스 오스틴이 올림픽 기록 2.39m(7 피트 10.09 인치)와 함께 우승을 한다.')\n"]}],"source":["k = 5\n","print(\"[Search query]\\n\", query, \"\\n\")\n","print(\"[Ground truth passage]\")\n","print(ground_truth, \"\\n\")\n","\n","for i in range(k):\n","  print(f\"Top-{i + 1} passage with score {dot_prod_scores.squeeze()[rank[i]]}:.4f\")\n","  pprint(valid_corpus[rank[i]])"]},{"cell_type":"markdown","metadata":{"id":"cicYTii7jZZC"},"source":["Ground Truth와 똑같거나 비슷한 Passage가 출력됐나요? 역시 Pretrained는 강력하군요.\n","### ❓ Dense Retrieval 코드를 class로 합쳐봅시다.\n","현재 구현된 모델은 굉장히 단순히 짜여졌습니다. 이미 Pretrain된 BERT 모델을 활용했는데, 다른 PLM은 어떨까요? 이를 다시 시도해보자니 코드가 너무 셀로 흩어져있어서 재사용이 어렵네요. 우선 클래스화를 진햏한 후에, `BERT`가 아닌 다른 PLM도 활용해봅시다."]},{"cell_type":"markdown","metadata":{"id":"on_Ay5_nbqEc"},"source":["❗ _Hint_   \n","Scratch부터 짜는게 많이 어려우신가요?\n","\n","만들어야하는 기능들의 파이프라인을 나열하고 하나씩 모듈화하는 습관을 들이는 것이 좋습니다. 순서대로 생각해볼까요?\n","\n","1. Setup   \n","    Naive한 `Dataset`을 받아서 이를 In-Batch Negative를 활용한 후 Dataloader로 변경해주는 코드가 있어야겠죠? 클래스 내에서 활용할 수 있도록 속성(attribute)으로 만들어줍시다. 이 코드를 위에서 활용한 `train` 함수에서 조금 차용해볼까요?\n","2. PLM을 주어진 Passage 와 In-batch negative 기법을 활용해서 훈련합니다.   \n","    이는 위에서 만든 `train` 함수를 약간 응용해서 재활용합시다.\n","3. 훈련한 PLM 을 통해 Query 를 Transform 합니다.\n","4. 내적을 통해 유사도를 구하고, 내림차순을 통해 유사한 Passage 를 Retrieval 합니다.\n","\n","위 4단계를 하나씩 함수로 구현한 후 Class로 합치면 훨씬 쉬울 겁니다!"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T08:06:47.410939Z","start_time":"2021-09-15T08:06:46.140856Z"},"id":"994wDYAujsLr"},"outputs":[],"source":["# 코드가 많아보이지만 주석이 더 많지롱\n","class DenseRetrieval:\n","    def __init__(self,\n","        args,\n","        dataset,\n","        num_neg,\n","        tokenizer,\n","        p_encoder,\n","        q_encoder\n","    ):\n","        \"\"\"\n","        Arguments:\n","            args (Huggingface Arguments):\n","                세팅과 학습에 필요한 설정값을 받습니다.\n","            dataset (datasets.Dataset):\n","                Huggingface의 Dataset을 받아옵니다.\n","            num_neg (int):\n","                In-batch negative 수행시 사용할 negative sample의 수를 받아옵니다.\n","            tokenizer (Callable):\n","                Tokenize할 함수를 받아옵니다.\n","                아래와 같은 함수들을 사용할 수 있습니다.\n","                - lambda x: x.split(' ')\n","                - Huggingface Tokenizer\n","                - konlpy.tag의 Mecab\n","            p_encoder (torch.nn.Module):\n","                Passage를 Dense Representation으로 임베딩시킬 모델입니다.\n","            q_encoder (torhc.nn.Module):\n","                Query를 Dense Representation으로 임베딩시킬 모델입니다.\n","\n","        Summary:\n","            학습과 추론에 필요한 객체들을 받아서 속성으로 저장합니다.\n","            객체가 instantiate될 때 in-batch negative가 생긴 데이터를 만들도록 함수를 수행합니다.\n","        \"\"\"\n","\n","        self.args = args\n","        self.dataset = dataset\n","        self.num_neg = num_neg\n","\n","        self.tokenizer = tokenizer\n","        self.p_encoder = p_encoder.to(args.device)\n","        self.q_encoder = q_encoder.to(args.device)\n","\n","        self.prepare_in_batch_negative(num_neg=num_neg)\n","\n","\n","    def prepare_in_batch_negative(self,\n","        dataset=None,\n","        num_neg=2,\n","        tokenizer=None\n","    ):\n","        \"\"\"\n","        Arguments:\n","            dataset (datasets.Dataset, default=None):\n","                Huggingface의 Dataset을 받아오면,\n","                in-batch negative를 추가해서 Dataloader를 만들어주세요.\n","            num_neg (int, default=2):\n","                In-batch negative 수행시 사용할 negative sample의 수를 받아옵니다.\n","            tokenizer (Callable, default=None):\n","                Tokenize할 함수를 받아옵니다.\n","                별도로 받아오지 않으면 속성으로 저장된 Tokenizer를 불러올 수 있게 짜주세요.\n","\n","        Note:\n","            모든 Arguments는 사실 이 클래스의 속성으로 보관되어 있기 때문에\n","            별도로 Argument를 직접 받지 않아도 수행할 수 있게 만들어주세요.\n","        \"\"\"\n","        if dataset is None:\n","            dataset = self.dataset\n","\n","        corpus = np.array(list(set([example[\"context\"] for example in dataset[\"train\"]])))\n","        p_with_neg = []\n","\n","        for c in dataset['train'][\"context\"]:\n","            while True:\n","                neg_idxs = np.random.randint(len(corpus), size=num_neg)\n","                if not c in corpus[neg_idxs]:\n","                    p_neg = corpus[neg_idxs]\n","\n","                    p_with_neg.append(c)\n","                    p_with_neg.extend(p_neg)\n","                    break\n","        \n","        if tokenizer is None:\n","            tokenizer = self.tokenizer\n","    \n","        q_seqs = tokenizer(\n","            dataset['train'][\"question\"],\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","        p_seqs = tokenizer(\n","            p_with_neg,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","        max_len = p_seqs[\"input_ids\"].size(-1)\n","        for key in p_seqs.keys():\n","            p_seqs[key] = p_seqs[key].view(-1, num_neg + 1, max_len)\n","        \n","        self.train_dataset = TensorDataset(\n","            p_seqs[\"input_ids\"], p_seqs[\"attention_mask\"], p_seqs[\"token_type_ids\"], \n","            q_seqs[\"input_ids\"], q_seqs[\"attention_mask\"], q_seqs[\"token_type_ids\"]\n","        )\n","\n","    def train(self,\n","        args=None\n","    ):\n","        \"\"\"\n","        Summary:\n","            train을 합니다. 위에 과제에서 이용한 코드를 활용합시다.\n","            encoder들과 dataloader가 속성으로 저장되어있는 점에 유의해주세요.\n","        \"\"\"\n","        pass\n","\n","\n","    def get_relevant_doc(self,\n","        query,\n","        k=1,\n","        args=None\n","    ):\n","        \"\"\"\n","        Arguments:\n","            query (str)\n","                문자열로 주어진 질문입니다.\n","            k (int, default=1)\n","                상위 몇 개의 유사한 passage를 뽑을 것인지 결정합니다.\n","            args (Huggingface Arguments, default=None)\n","                Configuration을 필요한 경우 넣어줍니다.\n","                만약 None이 들어오면 self.args를 쓰도록 짜면 좋을 것 같습니다.\n","\n","        Summary:\n","            1. query를 받아서 embedding을 하고\n","            2. 전체 passage와의 유사도를 구한 후\n","            3. 상위 k개의 문서 index를 반환합니다.\n","        \"\"\"\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T08:06:50.333519Z","start_time":"2021-09-15T08:06:47.419925Z"},"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["1b16d8e4c2d74aab9fdda9ae60c21441","58ca9dbe05d149fcb73677736541c1ce","92cbaf4e42694aca93e327941b1c9422","e4c5ce6351014015aa41d8a43fdca7d8","9407250e75c14524be3fa222b02c4f74","e38d794604bb409bb4d41a5bfef5eb61","0a78e445530c4d93a2ccce5bcda351da","3fe1fbff472c435c94c25c1736081373","430873d31e5c4770afd48183c1a8f1de","3ad885d798e64e35ae6705412494a52e","be78ee5fbd55487fb3dd0da23adbc154"]},"executionInfo":{"elapsed":2275,"status":"ok","timestamp":1632397200899,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"cBr57rLvkM68","outputId":"1bcc0a3e-90b7-44cb-c772-91a88df16f93"},"outputs":[{"name":"stderr","output_type":"stream","text":["Reusing dataset squad_kor_v1 (/root/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/18d4f44736b8ee85671f63cb84965bfb583fa0a4ff2df3c2e10eee9693796725)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b16d8e4c2d74aab9fdda9ae60c21441","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# 데이터셋과 모델은 아래와 같이 불러옵니다.\n","train_dataset = load_dataset(\"squad_kor_v1\")[\"train\"]\n","\n","# 메모리가 부족한 경우 일부만 사용하세요 !\n","num_sample = 1500\n","sample_idx = np.random.choice(range(len(train_dataset)), num_sample)\n","train_dataset = train_dataset[sample_idx]\n","\n","args = TrainingArguments(\n","    output_dir=\"dense_retireval\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=2,\n","    num_train_epochs=2,\n","    weight_decay=0.01\n",")\n","model_checkpoint = \"klue/bert-base\"\n","\n","# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","p_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)\n","q_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-09-15T08:06:50.335488Z","start_time":"2021-09-15T08:06:50.335488Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99005,"status":"ok","timestamp":1632397302609,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"8aUOE8VEyZ1v","outputId":"1b78b56c-a84c-4e5f-8d4a-43afe8dd0c2d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 750/750 [01:34<00:00,  7.91it/s]\n"]}],"source":["# Retriever는 아래와 같이 사용할 수 있도록 코드를 짜봅시다.\n","retriever = DenseRetrieval(\n","    args=args,\n","    dataset=train_dataset,\n","    num_neg=2,\n","    tokenizer=tokenizer,\n","    p_encoder=p_encoder,\n","    q_encoder=q_encoder\n",")\n","\n","retriever.train()\n","\n","query = \"유아인에게 타고난 배우라고 말한 드라마 밀회의 감독은?\"\n","results = retriever.get_relevant_doc(query=query, k=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1632397302609,"user":{"displayName":"‍조대현[ 대학원석·박사통합과정재학 / 인공지능학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01156684096009482818"},"user_tz":-540},"id":"YKKMfYhREui4","outputId":"ef512c8c-f8d6-4b6f-d124-24c438529faf"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Search query]\n"," 유아인에게 타고난 배우라고 말한 드라마 밀회의 감독은? \n","\n","[Predicted Passage]\n","('한편 2009년 헐리우드 메이저 영화 단독 주연으로 \"닌자 어쌔신\" 개봉하였고 2010년 6월 6일 아시아 한국인 최초로 미국 LA에서 '\n"," '열린 제 19회 \"2010 엠티비 무비 어워드(MTV Movie Awards)에서 최고의 액션스타상(Biggest Badass '\n"," 'Star)을 수상하였다. 아시아 최초 첫 단독 주연 액션스타상은 비가 최초이다. 또한 미국의 배우 안젤리나 졸리는 한 언론과의 인터뷰에서 '\n"," '비는 정말 대단하다며 극찬을 펼치기도 했었다. 2011년 아시아 연예인 최초로 미국 타임 세계에서 가장 영향력 있는 100인에 2회 '\n"," '선정되었다. 미국 타임 100인 선정은 타임 심사 위원들의 심사를 거쳐 선정하는데 가능하면 과거에 뽑힌 인물은 중복해서 선정하지 않는 게 '\n"," '원칙이고 인터넷 투표는 참고사항일뿐이라고 타임지는 밝혔습니다. 비는 지금까지 온라인 인기투표 리스트에 총 6회 이름이 올려줬다.[1]')\n"]}],"source":["print(f\"[Search Query] {query}\")\n","\n","indices = result[1]\n","for i, idx in enumerate(indices):\n","    print(f\"Top-{i + 1}th Passage (Index {idx})\")\n","    pprint(retriever.contexts[idx])"]},{"cell_type":"markdown","metadata":{"id":"TwE-zCr2CIiq"},"source":["#### ➕추가 과제: 다양한 기능 추가하기\n","현재 코드에서 불편한 부분이 있죠. 일단 너무 많은 기능을 한 class에 넣은 것도 문제, 메소드도 한 번에 너무 다양한 기능을 하는 것이 문제입니다. 메소드 내의 기능을 쪼개서 여러 메소드로 나누거나 데이터셋을 만드는 부분 같이 큰 기능을 다른 class로 분리해봅시다. (DPR 추가 과제는 예시 코드가 제공되지 않습니다. 다양하게 활용해보세요 !)"]},{"cell_type":"markdown","metadata":{"id":"sU8A2bpXnIOL"},"source":["### ❓ Sparse Retrieval과 Dense Retrieval을 둘 다 시도해보았습니다. 어떤 차이가 있을까요? 팀원들과 논의해보세요."]},{"cell_type":"markdown","metadata":{"id":"z8KO4AmLhr_G"},"source":["## ❓ 과제: Wikipedia documents에 대해 Passage Retrieval 실습하기"]},{"cell_type":"markdown","metadata":{"id":"fnvVrapPmcCO"},"source":["위에서 배운 Passage Retrieval을 Wikipedia에 있는 문서들로 진행해봅시다. 사실 위에서 두 클래스를 성공적으로 만들었다면, 데이터를 불러온 후 적용만 시키면 끝이 납니다.   \n","***별도의 예시코드가 제공되지 않습니다**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BC2AVU0m6OoV"},"outputs":[],"source":["# 츄라이 츄라이"]},{"cell_type":"markdown","metadata":{"id":"74EO3anZnbga"},"source":["만족스러운 결과가 나왔나요? 그렇지 않았다면 모델의 구조를 바꾸거나, 더 많은 training set으로 학습 시켜보세요 !"]},{"cell_type":"markdown","metadata":{"id":"A3j0VhH-kU9e"},"source":["### ❓ Take-home Question\n","이 QA 모델을 배포한다고 생각해봅시다. 성능이 좋아서 점점 이용자가 많아지는 상황입니다. 만약 동시에 1000명의 이용자가 Query 를 보내면 어떻게 될까요? 전체 Passage가 100,000 개라면, 이 유사도를 계산하고 비교하는 횟수는 ... 점점 많아질 것 같네요. 이 문제는 어떻게 해결하면 좋을까요?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCWS-F5haN6_"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"1012_MRC Mission 3 - Sparse & Dense Passage Retrieval.ipynb","provenance":[{"file_id":"1c9Vr7z_LBG2l9K4lVb40pu7Kk22hXQCp","timestamp":1614240569955},{"file_id":"1Q7iAXm_kwF_NHfOEGdViMCiPHnqoZlXe","timestamp":1613491158162}]},"interpreter":{"hash":"59a4978a0669016b4ccbe71ccd05c49f2f2a04fbb1f9995f1590c81f19124378"},"kernelspec":{"display_name":"Python 3.8.9 64-bit ('mission_venv': venv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"439.071px"},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"0a78e445530c4d93a2ccce5bcda351da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a8da4314be14db2a420e066d15c4a18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b16d8e4c2d74aab9fdda9ae60c21441":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92cbaf4e42694aca93e327941b1c9422","IPY_MODEL_e4c5ce6351014015aa41d8a43fdca7d8","IPY_MODEL_9407250e75c14524be3fa222b02c4f74"],"layout":"IPY_MODEL_58ca9dbe05d149fcb73677736541c1ce"}},"3a22cf7e6c644987994e3e0461656c55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ad885d798e64e35ae6705412494a52e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d2611ad087246688c3fc7b9b7c53b40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_614f4194be844ee8bd4432365f7aceff","placeholder":"​","style":"IPY_MODEL_ba00bee158e143bfbb25629b6f296839","value":"100%"}},"3fe1fbff472c435c94c25c1736081373":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"430873d31e5c4770afd48183c1a8f1de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58ca9dbe05d149fcb73677736541c1ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"614f4194be844ee8bd4432365f7aceff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62521bb1e4aa482d8a9cc70b8b0f05f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d2611ad087246688c3fc7b9b7c53b40","IPY_MODEL_c57cd63b63644d4b8816a596cc039f4f","IPY_MODEL_ebbbcf5247b14377ba5594c4b5f0762d"],"layout":"IPY_MODEL_0a8da4314be14db2a420e066d15c4a18"}},"83ae8317c78a4e3ea673e34f16c4c0ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92cbaf4e42694aca93e327941b1c9422":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a78e445530c4d93a2ccce5bcda351da","placeholder":"​","style":"IPY_MODEL_e38d794604bb409bb4d41a5bfef5eb61","value":"100%"}},"9407250e75c14524be3fa222b02c4f74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be78ee5fbd55487fb3dd0da23adbc154","placeholder":"​","style":"IPY_MODEL_3ad885d798e64e35ae6705412494a52e","value":" 2/2 [00:00&lt;00:00, 36.73it/s]"}},"ba00bee158e143bfbb25629b6f296839":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be78ee5fbd55487fb3dd0da23adbc154":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c57cd63b63644d4b8816a596cc039f4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7ea0c6822dd4e409f935facb5368857","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a22cf7e6c644987994e3e0461656c55","value":2}},"d93e9ad555854bbbb020482c3c929444":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e38d794604bb409bb4d41a5bfef5eb61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4c5ce6351014015aa41d8a43fdca7d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_430873d31e5c4770afd48183c1a8f1de","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3fe1fbff472c435c94c25c1736081373","value":2}},"e7ea0c6822dd4e409f935facb5368857":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebbbcf5247b14377ba5594c4b5f0762d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d93e9ad555854bbbb020482c3c929444","placeholder":"​","style":"IPY_MODEL_83ae8317c78a4e3ea673e34f16c4c0ab","value":" 2/2 [00:00&lt;00:00, 28.86it/s]"}}}}},"nbformat":4,"nbformat_minor":0}
