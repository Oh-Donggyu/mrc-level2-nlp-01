{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_from_disk, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_datasets = load_from_disk(\"/opt/ml/data/wiki_preprocessed_droped\")\n",
    "train_dataset = load_from_disk(\"/opt/ml/data/generator_dataset\")\n",
    "wiki_datasets.load_elasticsearch_index(\"text\", host=\"localhost\", port=\"9200\", es_index_name=\"wikipedia_contexts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'id', 'title', 'document_id', 'answers'],\n",
       "    num_rows: 35740\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55962/55962 [00:09<00:00, 5889.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dicts = []\n",
    "for wiki in tqdm(wiki_datasets):\n",
    "  wiki_dick = {}\n",
    "  wiki_dick['text'] = wiki['text']\n",
    "  wiki_dick['meta'] = {\n",
    "    'title': wiki['title'],\n",
    "    'document_id': wiki['document_id']\n",
    "  }\n",
    "  dicts.append(wiki_dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55962/55962 [00:00<00:00, 1071289.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_id = []\n",
    "for wiki in tqdm(dicts):\n",
    "  dict_id.append(wiki['meta']['document_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_context = []\n",
    "\n",
    "def drop_not_doc(datasets):\n",
    "  not_include = []\n",
    "  for data in tqdm(datasets):\n",
    "    if data['document_id'] not in dict_id:\n",
    "      not_include.append(data['document_id'])\n",
    "  def get_distance(a, b):\n",
    "    return abs(a - b)\n",
    "  def change_doc_id(example):\n",
    "    # if example['document_id'] not in not_include:\n",
    "    #   return example\n",
    "    doc = wiki_datasets.get_nearest_examples(\"text\", example['context'][:1024], k=1)\n",
    "    document_id = doc[1]['document_id'][0]\n",
    "    title = doc[1]['title'][0]\n",
    "    context_list = doc[1]['text'][0].split(example['answers']['text'][0])\n",
    "    if len(context_list) == 1:\n",
    "      error_context.append(example, context_list)\n",
    "      return example\n",
    "    distance = len(example['context'])\n",
    "    location = 0\n",
    "    for context in context_list:\n",
    "      location += len(context)\n",
    "      new_distance = get_distance(location, example['answers']['answer_start'][0])\n",
    "      if distance > new_distance:\n",
    "        distance = new_distance\n",
    "      else:\n",
    "        location -= len(context)\n",
    "        break\n",
    "    example['answers']['answer_start'][0] = location\n",
    "    example['document_id'] = document_id\n",
    "    example['title'] = title\n",
    "    example['context'] = example['answers']['text'][0].join(context_list)\n",
    "    return example\n",
    "  return datasets.map(change_doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35740/35740 [00:20<00:00, 1716.99it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0108c376e2ea4517aadbce10970312c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35740 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace/mrc_venv/lib/python3.8/site-packages/elasticsearch/connection/base.py:209: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "new_train_dataset = drop_not_doc(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /opt/ml/data/new_train_dataset/train/cache-989c01d5f466607c.arrow\n"
     ]
    }
   ],
   "source": [
    "search_error = new_train_dataset.filter(lambda example: example['context'][example['answers']['answer_start'][0]:example['answers']['answer_start'][0]+len(example['answers']['text'][0])] != example['answers']['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = load_from_disk('/opt/ml/data/new_train_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "        num_rows: 3351\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "        num_rows: 841\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  'train': new_train_dataset,\n",
    "  'validation': valid_dataset['validation']\n",
    "}\n",
    "train = DatasetDict(data)\n",
    "train.save_to_disk('new_gen_dataset') # 저장위치"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bac68cbaab3d35a4051d1e6f867fd4af3051b6908d059b1a63e6857e32e52681"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('mrc_venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
