{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_from_disk, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_datasets = load_from_disk(\"/opt/ml/data/wiki_preprocessed_droped\")\n",
    "train_dataset = load_from_disk(\"/opt/ml/data/train_dataset\")\n",
    "wiki_datasets.load_elasticsearch_index(\"text\", host=\"localhost\", port=\"9200\", es_index_name=\"wikipedia_contexts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55962/55962 [00:09<00:00, 6079.98it/s]\n"
     ]
    }
   ],
   "source": [
    "dicts = []\n",
    "for wiki in tqdm(wiki_datasets):\n",
    "  wiki_dick = {}\n",
    "  wiki_dick['content'] = wiki['text']\n",
    "  wiki_dick['meta'] = {\n",
    "    'title': wiki['title'],\n",
    "    'document_id': wiki['document_id']\n",
    "  }\n",
    "  dicts.append(wiki_dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dpr_dataset(target_dataset, dataset_name):\n",
    "  dpr_train_datas = []\n",
    "  def change_score(x):\n",
    "    x['score'] = 0\n",
    "    return x\n",
    "  for data in tqdm(target_dataset):\n",
    "    train_dict = {}\n",
    "    train_dict['dataset'] = dataset_name\n",
    "    train_dict['question'] = data['question']\n",
    "    train_dict['answers'] = data['answers']['text']\n",
    "    train_dict['positive_ctxs'] = [{\n",
    "      'title': data['title'],\n",
    "      'text': data['context'],\n",
    "      'score': 1000,\n",
    "      'title_score': 1,\n",
    "      'passage_id': data['document_id']\n",
    "    }]\n",
    "    negatives = []\n",
    "    query = data['question']\n",
    "    scores, retrieved_examples = wiki_datasets.get_nearest_examples(\"text\", query, k=100)\n",
    "    for index in range(100):\n",
    "      if retrieved_examples['document_id'][index] == data['document_id']:\n",
    "        continue\n",
    "      negative_dict = {\n",
    "        'title': retrieved_examples['title'][index],\n",
    "        'text': retrieved_examples['text'][index],\n",
    "        'score': scores[index],\n",
    "        'title_score': 0,\n",
    "        'passage_id': retrieved_examples['document_id'][index]\n",
    "      }\n",
    "      negatives.append(negative_dict)\n",
    "    train_dict['hard_negative_ctxs'] = random.sample(negatives[:15], 5)\n",
    "    train_dict['negative_ctxs'] = list(map(change_score, random.sample(negatives[50:], 10)))\n",
    "    dpr_train_datas.append(train_dict)\n",
    "  return dpr_train_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3952 [00:00<?, ?it/s]/opt/ml/code/ipynb_research/venv/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|██████████| 3952/3952 [05:01<00:00, 13.09it/s]\n",
      "100%|██████████| 240/240 [00:18<00:00, 13.11it/s]\n"
     ]
    }
   ],
   "source": [
    "dpr_train_datas = generate_dpr_dataset(train_dataset['train'], 'original_train')\n",
    "dpr_valid_datas = generate_dpr_dataset(train_dataset['validation'], 'original_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train.json', 'w', encoding='UTF-8') as file:\n",
    "  file.write(json.dumps(dpr_train_datas, ensure_ascii=False))\n",
    "with open('valid.json', 'w', encoding='UTF-8') as file:\n",
    "  file.write(json.dumps(dpr_valid_datas, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "977fda65bac41d30cd3f18c1e98e8fc3ad41bed726231322c7cb8b8621bf4c65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
